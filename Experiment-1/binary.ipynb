{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import ElasticNet, RidgeClassifier, Lasso, PassiveAggressiveClassifier, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from hyperopt import hp\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data from the uploaded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv(\"Data\\\\BP_features.csv\")\n",
    "labels = pd.read_csv(\"Data\\\\final_labels.csv\")\n",
    "labels = labels.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_normal = 0\n",
    "for i in labels:\n",
    "    count_normal += i\n",
    "count_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the datasets into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split ratio = 80:20 -> (441: 111)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_normal = 0\n",
    "for i in y_train:\n",
    "    count_normal += i\n",
    "count_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_evaluate_model(X_train, X_test, y_train, y_test, model, param_grid, model_name):\n",
    "    \n",
    "    # Hyperparameter tuning\n",
    "    \n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='roc_auc', n_jobs = -1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    best_params =  grid_search.best_params_\n",
    "    best_score =  grid_search.best_score_\n",
    "    # Predicting\n",
    "    y_train_pred = best_model.predict(X_train)\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Evaluation\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "    return best_model, train_accuracy, test_accuracy, best_params, best_score, train_f1, test_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = {\n",
    "    # 'Gradient Boosting': (GradientBoostingClassifier(random_state=42),{\n",
    "    #     'loss': ['log_loss', 'exponential'],\n",
    "    #     'criterion': ['friedman_mse', 'squared_error'],\n",
    "    #     'learning_rate': [0.01, 0.1, 0.2, 0.5, 1, 10, 100],\n",
    "    #     'n_estimators': [50, 100, 200, 300, 500],\n",
    "    #     'learning_rate': [0.01, 0.1, 0.2],\n",
    "    #     'max_depth': [3, 5, 7],\n",
    "\n",
    "    # }),\n",
    "\n",
    "    # 'K-Nearest Neighbors': (KNeighborsClassifier(),{\n",
    "    #     'n_neighbors': [1,3,5,7, 9, 11, 13, 17],\n",
    "    #     'leaf_size': [5, 10, 15, 20, 30, 40,  50],\n",
    "    #     'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    #     'weights': ['uniform', 'distance'],\n",
    "    #     'p': [1, 2, 4]\n",
    "    # }),\n",
    "\n",
    "    'XGBClassifier': (XGBClassifier(),{\n",
    "        'n_estimators': [50, 100, 150, 200, 300],  # Number of boosting rounds\n",
    "        'learning_rate': [0.01, 0.1, 0.3, 0.5, 1.0],  # Learning rate\n",
    "        # 'base_estimator__max_depth': [1, 2, 3]  # Depth of the base estimator (Decision Tree)\n",
    "\n",
    "        'alpha': [0, 0.001, 0.1, 1, 10, 100],\n",
    "        # 'max_depth': [3, 5, 7, 9],\n",
    "        # 'learning_rate': [0.1, 0.01, 0.001, 0.2, 0.5, 0.9],\n",
    "        'subsample': [0.6, 0.8, 1],\n",
    "        # 'learning_rate': [0.01, 0.1, 0.2],\n",
    "        # 'n_estimators': [100, 200, 300],\n",
    "        # 'max_depth': [3, 5, 7],\n",
    "        # 'min_child_weight': [1, 3, 5],\n",
    "        'gamma': [0, 0.001, 0.1, 1, 10, 100],\n",
    "        'lambda': [0, 0.001, 0.1, 1, 10, 100]\n",
    "        # 'subsample': [0.8, 1.0],\n",
    "        # 'colsample_bytree': [0.8, 1.0]\n",
    "    }),\n",
    "\n",
    "    # 'Logistic Regression': (LogisticRegression(max_iter = 5000, n_jobs=-1, random_state=42), {\n",
    "    #     'penalty': ['l1','l2', 'elasticnet'], \n",
    "    #     'C': [0.001,0.01,0.1,1,10,100,1000],\n",
    "    #     'solver': ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n",
    "    # }),\n",
    "    # 'Elastic Net': (ElasticNet(),{}),\n",
    "    # 'Ridge': (RidgeClassifier(random_state=42, max_iter=5000),{\n",
    "    #     'solver': [ 'auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga', 'lbfgs'],\n",
    "    #     'alpha': [0.001, 0.01, 0.05, 0.1, 0.5, 1, 2, 5, 10, 100, 1000],\n",
    "    #     'positive': [True, False],\n",
    "    #     'fit_intercept': [True, False],\n",
    " \n",
    "    # }),\n",
    "    # 'Lasso': (Lasso(),{}),\n",
    "    # 'Extra Trees': (ExtraTreesClassifier(random_state=42, n_jobs=-1),{\n",
    "    #     'n_estimators': [100, 150, 200, 250, 300], \n",
    "    #     'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    #     'max_depth': [None, 10, 20, 30],\n",
    "    #     'min_samples_split': [2, 5, 10],\n",
    "    #     'min_samples_leaf': [1, 2, 4],\n",
    "    #     'max_features': ['auto', 'sqrt', 'log2']\n",
    "    # }),\n",
    "    # 'AdaBoost': (AdaBoostClassifier(random_state=42, algorithm='SAMME'),{\n",
    "    #     'n_estimators': [50, 70, 90, 120, 160, 180, 200],\n",
    "    #     'learning_rate': [0.001, 0.01, 0.1 , 0.5, 0.8, 1, 1.5, 5, 10, 100]\n",
    "    #     'algorithm': ['SAMME', 'SAMME.R']\n",
    "    # }),\n",
    "\n",
    "    # 'Passive Aggressive': (PassiveAggressiveClassifier(max_iter=5000, random_state=42, n_jobs=-1), {\n",
    "    #     'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    #     'loss': ['hinge', 'squared_hinge']\n",
    "    # }),\n",
    "    # 'Support Vector Classification': (SVC(random_state=42), {\n",
    "    #     'C': [0.1, 1, 10, 100, 1000],  \n",
    "    #     'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "    #     'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    #     'decision_function_shape': ['ovo', 'ovr']\n",
    "    # }),\n",
    "\n",
    "    # 'Decision Trees': (DecisionTreeClassifier(random_state=42), {\n",
    "    #     'max_depth': [None, 10, 20, 30],\n",
    "    #     'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    #     'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    #     'splitter': ['best', 'random'],\n",
    "    #     'min_samples_split': [2, 5, 10],\n",
    "    #     'min_samples_leaf': [1, 2, 4],\n",
    "\n",
    "    # }),\n",
    "\n",
    "    # 'Random Forest': (RandomForestClassifier(random_state=42, n_jobs=-1), {\n",
    "    #     'n_estimators': [100, 150, 200, 250, 300], \n",
    "    #     'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    #     'max_depth': [None, 10, 20, 30],\n",
    "    #     'min_samples_split': [2, 5, 10],\n",
    "    #     'min_samples_leaf': [1, 2, 4],\n",
    "    #     'max_features': ['auto', 'sqrt', 'log2']\n",
    "    # }),\n",
    "    # 'Naive Bayes': (GaussianNB(), {'var_smoothing': np.logspace(0,-9, num=100)}),\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_models = {}\n",
    "result = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for model_name, (model, param_grid) in models.items():\n",
    "    best_model, train_accuracy, test_accuracy, best_params, best_score, train_f1, test_f1 = train_evaluate_model(X_train, X_test, y_train, y_test, model, param_grid, model_name)\n",
    "    best_models[model_name] = best_model\n",
    "    result[model_name] = [train_accuracy, test_accuracy, train_f1, test_f1, best_score, best_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Test F1</th>\n",
       "      <th>Best Score</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.846847</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.866184</td>\n",
       "      <td>{'alpha': 1, 'gamma': 0.001, 'lambda': 0, 'lea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Train Accuracy Test Accuracy Train F1   Test F1 Best Score  \\\n",
       "XGBClassifier            1.0      0.846847      1.0  0.604651   0.866184   \n",
       "\n",
       "                                                     Best Params  \n",
       "XGBClassifier  {'alpha': 1, 'gamma': 0.001, 'lambda': 0, 'lea...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(result).T\n",
    "results.columns = ['Train Accuracy', 'Test Accuracy', 'Train F1', 'Test F1', 'Best Score', 'Best Params']\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in models.keys():\n",
    "    # print(results[i])\n",
    "    path = i + \".json\"\n",
    "    results.T[i].to_json(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1,\n",
       " 'gamma': 0.001,\n",
       " 'lambda': 0,\n",
       " 'learning_rate': 0.5,\n",
       " 'n_estimators': 50,\n",
       " 'subsample': 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['Best Params'].iloc[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
